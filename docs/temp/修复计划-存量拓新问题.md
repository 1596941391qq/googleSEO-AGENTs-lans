# 修复计划：存量拓新模式问题修复

**创建时间**: 2026-01-02  
**状态**: 计划阶段，待实施

---

## 📋 四种模式说明

系统包含四种独立的工作模式，需要严格区分：

### 1. 蓝海发现的关键词挖掘（Keyword Mining）
- **输入**: 种子关键词
- **流程**: 
  1. `startMining` (blue-ocean) → `runMiningLoop`
  2. 循环执行 `executeKeywordMining`：
     - 生成关键词（Agent 1）
     - SE Ranking 数据获取
     - SERP 分析
     - 排名概率分析
  3. 继续循环挖掘，直到挖到高概率上首页的词
- **输出**: 关键词列表（带排名概率，包含高概率关键词）
- **文件**: `App.tsx` (startMining, runMiningLoop), `api/_shared/services/keyword-mining-service.ts`

### 2. 蓝海发现的跨市场调查（Batch Analysis）
- **输入**: 从蓝海发现的关键词挖掘结果中选择的关键词列表
- **流程**: 
  1. 调用 `/api/batch-translate-analyze`
  2. 批量分析所有关键词上首页的概率：
     - SE Ranking 数据获取
     - SERP 分析
     - 排名概率分析
- **输出**: 关键词列表（带完整分析数据，包含所有关键词的上首页概率）
- **文件**: `App.tsx`, `api/batch-translate-analyze.ts`

### 3. 存量拓新的关键词挖掘（Keyword Mining）
- **输入**: 网站URL
- **流程**: 
  1. `startWebsiteAudit` → `/api/website-audit`：
     - 网站内容获取（Firecrawl）
     - 竞争对手关键词获取（DataForSEO）
     - AI 分析找出关键词机会
  2. **然后进行 keyword mining 循环挖掘**：
     - 使用 `executeKeywordMining` 或类似函数
     - 循环生成关键词
     - SE Ranking + SERP + 排名概率分析
     - 继续循环，直到挖出高概率上首页的词
- **输出**: 关键词列表（带排名概率，包含高概率关键词）
- **文件**: `App.tsx` (startWebsiteAudit), `api/website-audit.ts`, `api/_shared/services/keyword-mining-service.ts`

### 4. 存量拓新的跨市场调查（Batch Analysis）
- **输入**: 选定网址
- **流程**: 
  1. 从网址提取关键词（可能调用 `/api/website-audit` 获取初始关键词）
  2. 调用 `/api/batch-translate-analyze`
  3. 批量分析所有关键词上首页的概率：
     - SE Ranking 数据获取
     - SERP 分析
     - 排名概率分析
- **输出**: 关键词列表（带完整分析数据，包含所有关键词的上首页概率）
- **文件**: `App.tsx`, `api/website-audit.ts`, `api/batch-translate-analyze.ts`

**关键区别**：
- **关键词挖掘（Keyword Mining）**：循环挖掘，直到找到高概率上首页的词（使用 `executeKeywordMining` 服务，循环执行）
- **跨市场调查（Batch Analysis）**：批量分析已有关键词的上首页概率（使用 `batch-translate-analyze` API，一次性分析）

---

## 📋 问题概述

用户反馈了三个关键问题：

1. **问题1**: 存量模式下输入的是 `302.ai` 但分析的是 `manus.im`，说明输入框里的网址没有正确绑定
2. **问题2**: SE Ranking 的竞争对手 API 使用失败（返回 400 错误），建议换成 DataForSEO 的 API
3. **问题3**: 存量拓新的关键词挖掘工作流可能走成了跨市场调查的工作流，逻辑不对

---

## 🔍 问题分析

### 问题1：输入框网址绑定错误

**根本原因**：
- 在 `App.tsx` 的 `startWebsiteAudit` 函数（第4796行）中，只检查了 `selectedWebsite`，没有检查 `manualWebsiteUrl`
- 在 `startMining` 函数（第4704行）中，验证逻辑也只检查了 `selectedWebsite`
- 当用户手动输入 URL 但没有从下拉列表选择时，`selectedWebsite` 可能为 `null` 或者是之前选择的网站（如 `manus.im`）

**影响范围**：
- `App.tsx` 中的 `startWebsiteAudit` 函数
- `App.tsx` 中的 `startMining` 函数
- 网站选择逻辑

**修复方案**：
1. 修改 `startWebsiteAudit` 函数，优先使用 `manualWebsiteUrl`（如果用户手动输入了）
2. 修改 `startMining` 函数，验证逻辑也要检查 `manualWebsiteUrl`
3. 当使用 `manualWebsiteUrl` 时，需要构建一个临时的网站对象传递给 API

---

### 问题2：SE Ranking 竞争对手 API 失败

**根本原因**：
- 当前在 `api/_shared/agents/agent-1-website-audit.ts` 中使用的是 SE Ranking 的 `getDomainCompetitors` API
- 该 API 返回 400 错误，可能因为：
  - API 端点不可用
  - 参数格式不正确
  - API 权限问题

**影响范围**：
- `api/_shared/agents/agent-1-website-audit.ts` 中的 `auditWebsiteForKeywords` 函数
- `api/_shared/tools/se-ranking-domain.ts` 中的 `getDomainCompetitors` 函数

**修复方案**：
1. 在 `api/_shared/tools/dataforseo.ts` 中添加 `getDomainCompetitors` 函数
2. 使用 DataForSEO 的 `/v3/dataforseo_labs/google/competitors_domain/live` 端点
3. 修改 `agent-1-website-audit.ts`，将 SE Ranking 的调用替换为 DataForSEO
4. 保持接口兼容性，确保返回的数据格式一致

**DataForSEO API 参考**：
- 端点：`POST https://api.dataforseo.com/v3/dataforseo_labs/google/competitors_domain/live`
- 请求体格式：`[{ "target": "example.com", "location_code": 2840, "language_code": "en" }]`
- 响应格式：需要解析 `tasks[0].result[0].items` 数组

---

### 问题3：工作流逻辑错误

**根本原因**：
- 存量拓新的关键词挖掘应该执行：网站分析 → 关键词发现 → **keyword mining 循环挖掘** → 直到找到高概率上首页的词
- 但当前代码可能只执行了：网站分析 → 批量分析（`batch-translate-analyze`），**缺少了 keyword mining 循环挖掘步骤**
- 批量分析（`batch-translate-analyze`）是跨市场调查的工作流，不是关键词挖掘的工作流

**正确的存量拓新关键词挖掘流程**：
1. **Step 1**: 网站内容获取（Firecrawl）
2. **Step 2**: 竞争对手关键词获取（DataForSEO）
3. **Step 3**: AI 分析找出初始关键词机会
4. **Step 4**: **Keyword Mining 循环挖掘**（类似 `runMiningLoop`）：
   - 使用 `executeKeywordMining` 服务
   - 循环生成关键词（基于初始关键词作为种子）
   - SE Ranking 数据获取
   - SERP 分析
   - 排名概率分析
   - 继续循环，直到挖出高概率上首页的词
5. **Step 5**: 返回关键词列表（带排名概率，包含高概率关键词）

**错误的流程**（当前可能存在的问题）：
- ❌ 只执行了网站分析 → 批量分析（`batch-translate-analyze`），缺少 keyword mining 循环
- ❌ 把批量分析（跨市场调查）当成了关键词挖掘
- ❌ 没有循环挖掘，无法持续找到高概率上首页的词

**影响范围**：
- `App.tsx` 中的 `startWebsiteAudit` 函数（约第5151行）
- `api/website-audit.ts` API 端点
- `api/_shared/agents/agent-1-website-audit.ts` 中的工作流逻辑
- `api/batch-translate-analyze.ts` 批量分析逻辑

**修复方案**：
1. 修改 `startWebsiteAudit` 函数，添加 keyword mining 循环：
   - ✅ Step 1: 调用 `/api/website-audit` 获取初始关键词机会
   - ✅ Step 2: **调用 keyword mining 服务进行循环挖掘**（类似 `runMiningLoop`）
     - 使用 `executeKeywordMining` 服务
     - 将初始关键词作为种子，继续挖掘
     - 循环执行，直到找到高概率上首页的词
   - ❌ **不应该**调用 `/api/batch-translate-analyze`（那是跨市场调查用的）
   - ❌ **不应该**调用 `runEnhancedDeepDive`（那是跨市场调查用的）

2. 创建或修改存量拓新的 keyword mining 循环函数：
   - 参考 `runMiningLoop` 函数的实现
   - 但使用存量拓新发现的初始关键词作为种子
   - 循环调用 `executeKeywordMining` 服务
   - 持续挖掘直到找到高概率上首页的词

3. 检查 `agent-1-website-audit.ts`，确保工作流正确：
   - Step 1: 获取网站内容（Firecrawl `scrapeWebsite`）
   - Step 2: 获取竞争对手关键词（DataForSEO `getDomainCompetitors` + `getDomainKeywords`）
   - Step 3: AI 分析（调用 Gemini API）
   - Step 4: 返回初始关键词列表（作为 keyword mining 的种子）

---

## 📝 详细修复步骤

### Phase 1: 修复输入框网址绑定问题

**文件**: `App.tsx`

1. **修改 `startWebsiteAudit` 函数（约第4796行）**：
   ```typescript
   // 修改前：
   const websiteToUse = continueExisting && taskWebsiteUrl
     ? { id: taskWebsiteId, url: taskWebsiteUrl, domain: ... }
     : selectedWebsite;
   
   // 修改后：
   // 优先使用手动输入的 URL，否则使用选择的网站
   let websiteToUse;
   if (continueExisting && taskWebsiteUrl) {
     websiteToUse = { id: taskWebsiteId, url: taskWebsiteUrl, domain: ... };
   } else if (manualWebsiteUrl.trim()) {
     // 用户手动输入了 URL，构建临时网站对象
     const cleanUrl = manualWebsiteUrl.trim();
     const urlWithProtocol = /^https?:\/\//i.test(cleanUrl) 
       ? cleanUrl 
       : `https://${cleanUrl}`;
     const domain = new URL(urlWithProtocol).hostname.replace(/^www\./, '');
     websiteToUse = {
       id: `manual-${Date.now()}`,
       url: urlWithProtocol,
       domain: domain,
     };
   } else {
     websiteToUse = selectedWebsite;
   }
   ```

2. **修改 `startMining` 函数（约第4704行）**：
   ```typescript
   // 修改前：
   if (miningMode === "existing-website-audit" && !selectedWebsite) {
     // 错误提示
   }
   
   // 修改后：
   if (miningMode === "existing-website-audit" && !selectedWebsite && !manualWebsiteUrl.trim()) {
     setState((prev) => ({
       ...prev,
       error: state.uiLanguage === "zh"
         ? "请先选择或输入要分析的网站"
         : "Please select or enter a website to analyze",
     }));
     return;
   }
   ```

---

### Phase 2: 替换 SE Ranking 为 DataForSEO API

**文件**: `api/_shared/tools/dataforseo.ts`

1. **添加 `getDomainCompetitors` 函数**：
   ```typescript
   export interface DomainCompetitor {
     domain: string;
     title?: string;
     commonKeywords: number;
     organicTraffic: number;
     totalKeywords: number;
     gapKeywords?: number;
     gapTraffic?: number;
   }
   
   export async function getDomainCompetitors(
     domain: string,
     locationCode: number = 2840, // 默认美国
     limit: number = 5
   ): Promise<DomainCompetitor[]> {
     // 实现 DataForSEO API 调用
     // 端点: /v3/dataforseo_labs/google/competitors_domain/live
     // 请求体: [{ "target": domain, "location_code": locationCode, "language_code": "en" }]
   }
   ```

2. **实现细节**：
   - 使用 Basic Auth 认证
   - 处理速率限制（429 错误）
   - 解析响应格式：`tasks[0].result[0].items`
   - 转换为统一的 `DomainCompetitor` 格式
   - 添加错误处理和日志

**文件**: `api/_shared/agents/agent-1-website-audit.ts`

1. **替换导入**：
   ```typescript
   // 修改前：
   import { getDomainKeywords, getDomainCompetitors } from '../tools/se-ranking-domain.js';
   
   // 修改后：
   import { getDomainKeywords } from '../tools/se-ranking-domain.js';
   import { getDomainCompetitors } from '../tools/dataforseo.js';
   ```

2. **修改调用逻辑（约第103行）**：
   ```typescript
   // 修改前：
   const competitors = await getDomainCompetitors(websiteDomain, targetLanguage === 'zh' ? 'cn' : 'us', 5);
   
   // 修改后：
   // 将语言代码转换为 DataForSEO 的 location_code
   const locationCode = targetLanguage === 'zh' ? 2166 : 2840; // 2166=中国, 2840=美国
   const competitors = await getDomainCompetitors(websiteDomain, locationCode, 5);
   ```

---

### Phase 3: 修复工作流逻辑

**文件**: `api/_shared/agents/agent-1-website-audit.ts`

1. **检查工作流步骤**，确保逻辑正确：
   - ✅ Step 1: 获取网站内容（Firecrawl `scrapeWebsite`）
   - ✅ Step 2: 获取竞争对手关键词（DataForSEO `getDomainCompetitors` + `getDomainKeywords`）
   - ✅ Step 3: AI 分析（调用 Gemini API）
   - ✅ Step 4: 返回初始关键词列表（作为 keyword mining 的种子）
   - ❌ 不应该调用：批量分析（`batch-translate-analyze`，那是跨市场调查用的）

2. **添加日志**，确保每个步骤都正确执行：
   ```typescript
   console.log(`[Website Audit] Step X: [步骤描述]`);
   ```

**文件**: `App.tsx`

1. **修改 `startWebsiteAudit` 函数**（约第4786行），添加 keyword mining 循环：
   - ✅ Step 1: 调用 `/api/website-audit` 获取初始关键词机会
   - ✅ Step 2: **调用 keyword mining 循环挖掘**（类似 `runMiningLoop`）：
     ```typescript
     // 使用初始关键词作为种子，进行循环挖掘
     const initialKeywords = result.keywords.map(k => k.keyword);
     await runWebsiteAuditMiningLoop(initialKeywords, currentTaskId);
     ```
   - ✅ Step 3: 显示关键词列表（带排名概率，包含高概率关键词）
   - ❌ **删除**调用 `/api/batch-translate-analyze` 的代码（那是跨市场调查用的）
   - ❌ 不应该调用：
     - `runEnhancedDeepDive` 或 `executeDeepDive`（那是跨市场调查用的）
     - 搜索引擎偏好分析（那是 Deep Dive 用的）
     - SEO策略生成（那是 Deep Dive 用的）

2. **创建 `runWebsiteAuditMiningLoop` 函数**（参考 `runMiningLoop`）：
   ```typescript
   const runWebsiteAuditMiningLoop = async (
     seedKeywords: string[],
     taskId: string
   ) => {
     let currentRound = 0;
     let allKeywords: KeywordData[] = [];
     
     while (!stopMiningRef.current) {
       currentRound++;
       
       // 使用种子关键词进行挖掘
       const miningResult = await executeKeywordMining({
         seedKeyword: seedKeywords.join(', '), // 使用初始关键词作为种子
         targetLanguage: state.targetLanguage,
         existingKeywords: allKeywords.map(k => k.keyword),
         roundIndex: currentRound,
         wordsPerRound: state.wordsPerRound || 10,
         miningStrategy: state.miningStrategy || 'horizontal',
         // ... 其他参数
       });
       
       // 分析关键词
       const analyzedKeywords = await analyzeKeywords(miningResult.keywords);
       allKeywords.push(...analyzedKeywords);
       
       // 检查是否有高概率关键词
       const highProbCount = analyzedKeywords.filter(
         k => k.probability === ProbabilityLevel.HIGH
       ).length;
       
       // 如果找到足够的高概率关键词，可以停止或继续
       // ...
     }
   };
   ```

3. **区分关键词挖掘和跨市场调查**：
   - **关键词挖掘**：`startWebsiteAudit` → `/api/website-audit` → `runWebsiteAuditMiningLoop` → 返回关键词列表（循环挖掘）
   - **跨市场调查**：用户选择关键词列表 → `/api/batch-translate-analyze` → 批量分析上首页概率
   - 确保这两个流程完全独立，不会混淆

---

## 🧪 测试计划

### 测试1：输入框绑定测试
1. 切换到存量拓新模式
2. 手动输入 `302.ai`（不选择下拉列表）
3. 点击"开始分析"按钮
4. **预期结果**：应该分析 `302.ai`，而不是其他网站

### 测试2：DataForSEO API 测试
1. 运行存量拓新分析
2. 检查控制台日志
3. **预期结果**：
   - 应该调用 DataForSEO API
   - 应该成功获取竞争对手数据
   - 不应该出现 400 错误

### 测试3：工作流逻辑测试
1. 运行存量拓新关键词挖掘
2. 检查日志，确认工作流步骤
3. **预期结果**：
   - 应该执行：
     - Step 1: 网站内容获取（Firecrawl）
     - Step 2: 竞争对手关键词获取（DataForSEO）
     - Step 3: AI 分析找出关键词机会
     - Step 4: 批量分析（SE Ranking + SERP + 排名概率）
     - Step 5: 返回关键词列表（带完整分析数据）
   - 不应该执行：
     - 关键词生成 Agent（那是蓝海发现用的）
     - Deep Dive 流程（搜索引擎偏好、SEO策略生成，那是跨市场调查用的）
     - 跳过批量分析步骤

---

## 📌 注意事项

1. **向后兼容性**：
   - 保持 `DomainCompetitor` 接口不变
   - 确保返回的数据格式一致

2. **错误处理**：
   - DataForSEO API 可能也需要处理速率限制
   - 如果 DataForSEO 失败，可以考虑回退到其他方案或返回空数组

3. **性能考虑**：
   - DataForSEO API 可能有延迟，需要添加超时控制
   - 考虑添加缓存机制

4. **代码清理**：
   - 如果不再使用 SE Ranking 的 `getDomainCompetitors`，可以考虑标记为废弃
   - 但暂时保留，以防需要回退

---

## ✅ 验收标准

- [ ] 问题1：输入框正确绑定，手动输入的 URL 能够正确使用
- [ ] 问题2：DataForSEO API 成功替换 SE Ranking，不再出现 400 错误
- [ ] 问题3：工作流逻辑正确，存量拓新关键词挖掘流程完整：
  - [ ] 执行网站内容获取 → 竞争对手关键词获取 → AI 分析 → **Keyword Mining 循环挖掘** → 返回关键词列表
  - [ ] Keyword Mining 循环正确执行（循环调用 `executeKeywordMining`，直到找到高概率上首页的词）
  - [ ] 不执行批量分析（`batch-translate-analyze`，那是跨市场调查用的）
  - [ ] 不执行 Deep Dive 流程（跨市场调查用的）
  - [ ] 循环挖掘持续进行，不会只执行一次就结束

---

## 📅 实施时间表

- **Phase 1**: 1-2 小时（输入框绑定修复）
- **Phase 2**: 2-3 小时（DataForSEO API 集成）
- **Phase 3**: 1-2 小时（工作流逻辑检查和修复）
- **测试**: 1 小时
- **总计**: 5-8 小时
